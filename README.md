# Sistema de DetecciÃ³n de Fraude en Tiempo Real

## ğŸ“‹ DescripciÃ³n
Sistema de detecciÃ³n de fraude que procesa transacciones en tiempo real utilizando mÃºltiples modelos de Machine Learning. Integra FastAPI, Kafka, PostgreSQL y modelos de ML para proporcionar predicciones de fraude instantÃ¡neas.

## ğŸ—ï¸ Arquitectura
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kafka     â”‚â”€â”€â”€â–¶â”‚   FastAPI   â”‚â”€â”€â”€â–¶â”‚ PostgreSQL  â”‚
â”‚ (Producer)  â”‚    â”‚ (Consumer)  â”‚    â”‚ (Storage)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   Models    â”‚
                   â”‚ (ML Models) â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos
- Python 3.9+
- Docker y Docker Compose
- PostgreSQL (opcional, se incluye en Docker)

### InstalaciÃ³n Local

1. **Clonar el repositorio**
```bash
git clone <repository-url>
cd app-3
```

2. **Crear entorno virtual**
```bash
python -m venv venv
# Windows
.\venv\Scripts\Activate.ps1
# Linux/Mac
source venv/bin/activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Configurar variables de entorno**
```bash
# Crear archivo .env
cp .env.example .env
# Editar .env con tus credenciales
```

5. **Ejecutar con Docker (recomendado)**
```bash
docker-compose up -d
```

### InstalaciÃ³n Solo Docker
```bash
docker-compose up -d
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno (.env)
```env
# Base de datos
DATABASE_URL=postgresql://fraud_user:fraud_password@localhost:5432/fraud_detection

# Kafka
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_SASL_MECHANISMS=PLAIN
KAFKA_SECURITY_PROTOCOL=PLAINTEXT
KAFKA_TOPIC_INPUT=transactions_stream
KAFKA_TOPIC_OUTPUT=fraud_predictions

# AplicaciÃ³n
ENVIRONMENT=development
LOG_LEVEL=INFO
MODEL_PATH=./model
```

## ğŸ¯ Uso

### Iniciar la AplicaciÃ³n
```bash
# Desarrollo local
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Con Docker
docker-compose up -d
```

### Endpoints Disponibles

- **GET** `/health` - Estado de la aplicaciÃ³n
- **GET** `/start-consuming` - Iniciar consumo de transacciones
- **GET** `/transaction/{transaction_id}` - Obtener resultado de transacciÃ³n

### Enviar Transacciones
```bash
# Ejemplo de transacciÃ³n
curl -X POST "http://localhost:8000/transaction" \
  -H "Content-Type: application/json" \
  -d '{
    "transaction_id": "12345",
    "amount": 100.50,
    "time": 1234567890,
    "v1": 0.1,
    "v2": 0.2,
    ...
    "v28": 0.28
  }'
```

## ğŸ¤– Modelos de Machine Learning

El sistema utiliza 5 modelos diferentes:

1. **RegresiÃ³n LogÃ­stica** (`logistic_regression_model.pkl`)
2. **K-Nearest Neighbors** (`knears_neighbors_model.pkl`)
3. **Support Vector Classifier** (`svc_model.pkl`)
4. **Ãrbol de DecisiÃ³n** (`decision_tree_model.pkl`)
5. **Red Neuronal Keras** (`undersample_model.h5`)

## ğŸ“Š Monitoreo

### Kafka UI
- URL: http://localhost:8080
- Monitoreo de tÃ³picos y mensajes

### Logs
```bash
# Ver logs de la aplicaciÃ³n
docker-compose logs -f app

# Ver logs de todos los servicios
docker-compose logs -f
```

## ğŸ§ª Testing

### Ejecutar Tests
```bash
# Instalar dependencias de desarrollo
pip install -r requirements-dev.txt

# Ejecutar tests
pytest tests/
```

### Tests de IntegraciÃ³n
```bash
# Test completo del flujo
python -m pytest tests/test_integration.py -v
```

## ğŸš€ Despliegue

### ProducciÃ³n
```bash
# Construir imagen de producciÃ³n
docker build -t fraud-detection:latest .

# Ejecutar en producciÃ³n
docker-compose -f docker-compose.prod.yml up -d
```

### Variables de Entorno de ProducciÃ³n
```env
ENVIRONMENT=production
LOG_LEVEL=WARNING
DATABASE_URL=<production-db-url>
KAFKA_BOOTSTRAP_SERVERS=<production-kafka-url>
```

## ğŸ“ Estructura del Proyecto

```
app-3/
â”œâ”€â”€ main.py                 # AplicaciÃ³n FastAPI principal
â”œâ”€â”€ config.py              # ConfiguraciÃ³n de la aplicaciÃ³n
â”œâ”€â”€ db.py                  # Operaciones de base de datos
â”œâ”€â”€ kafka_client.py        # Cliente Kafka
â”œâ”€â”€ prediction.py          # Modelos de ML y predicciones
â”œâ”€â”€ requirements.txt       # Dependencias de Python
â”œâ”€â”€ Dockerfile            # ConfiguraciÃ³n de Docker
â”œâ”€â”€ docker-compose.yml     # OrquestaciÃ³n de servicios
â”œâ”€â”€ model/                 # Modelos de ML entrenados
â”‚   â”œâ”€â”€ logistic_regression_model.pkl
â”‚   â”œâ”€â”€ knears_neighbors_model.pkl
â”‚   â”œâ”€â”€ svc_model.pkl
â”‚   â”œâ”€â”€ decision_tree_model.pkl
â”‚   â””â”€â”€ undersample_model.h5
â”œâ”€â”€ tests/                 # Tests unitarios e integraciÃ³n
â”œâ”€â”€ schemas.py             # Esquemas Pydantic
â”œâ”€â”€ logging_config.py      # ConfiguraciÃ³n de logging
â””â”€â”€ README.md             # Esta documentaciÃ³n
```

## ğŸ”’ Seguridad

- AutenticaciÃ³n JWT (pendiente)
- ValidaciÃ³n de entrada con Pydantic
- Rate limiting (pendiente)
- HTTPS en producciÃ³n (pendiente)

## ğŸ“ˆ MÃ©tricas y Monitoreo

- Health checks automÃ¡ticos
- Logs estructurados
- MÃ©tricas de rendimiento (pendiente)
- Alertas automÃ¡ticas (pendiente)

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crear rama feature (`git checkout -b feature/AmazingFeature`)
3. Commit cambios (`git commit -m 'Add AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

## ğŸ“ Soporte

Para soporte tÃ©cnico, contactar:
- Email: soporte@fraud-detection.com
- Issues: GitHub Issues

## ğŸ”„ Changelog

### v1.0.0
- ImplementaciÃ³n inicial del sistema
- 5 modelos de ML integrados
- API REST con FastAPI
- IntegraciÃ³n con Kafka y PostgreSQL
- DockerizaciÃ³n completa
